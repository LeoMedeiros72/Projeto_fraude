# -*- coding: utf-8 -*-
"""projeto_fraude2

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1ghGyyCGmk-N52q3tB2M6bdwJPl5ergyR

## Introdução

Este projeto tem como objetivo construir um modelo de machine learning para detecção de transações bancárias fraudulentas com base em um conjunto de dados transacional.

O foco está em identificar comportamentos suspeitos com alta precisão e recall, mesmo em cenários de dados desbalanceados.
"""

import pandas as pd

# Conectando ao Drive
from google.colab import drive
drive.mount('/content/drive')

# Caminho do arquivo no Google Drive (credicard.csv disponível também no link para download: 'https://www.kaggle.com/datasets/mlg-ulb/creditcardfraud')
data_path = "/content/drive/MyDrive/Projeto_Fraude/creditcard.csv"

# Carrega o DataFrame
df = pd.read_csv(data_path)
df.head()

# Verificar valores ausentes em cada coluna
df.isnull().sum()

import seaborn as sns
import matplotlib.pyplot as plt

# Calcular a correlação
corr = df.corr()

# Exibir o mapa de calor da correlação
plt.figure(figsize=(12, 8))
sns.heatmap(corr, annot=True, cmap='coolwarm', fmt='.2f')
plt.title('Mapa de Calor de Correlação')
plt.show()

from sklearn.preprocessing import StandardScaler
from sklearn.model_selection import train_test_split

# Variável dependente (Class) e variáveis independentes (X)
X = df.drop('Class', axis=1)
y = df['Class']

# Normalizando os dados
scaler = StandardScaler()
X_scaled = scaler.fit_transform(X)

# Dividir os dados em treinamento e teste (80% treinamento, 20% teste)
X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)

from sklearn.linear_model import LogisticRegression
from sklearn.metrics import accuracy_score, classification_report

# Treinar o modelo de regressão logística
model = LogisticRegression()
model.fit(X_train, y_train)

# Fazer previsões
y_pred = model.predict(X_test)

# Avaliar a performance
print(f'Acurácia: {accuracy_score(y_test, y_pred):.4f}')
print('Relatório de Classificação:')
print(classification_report(y_test, y_pred))

from imblearn.over_sampling import SMOTE

# Aplicar SMOTE para balancear as classes
smote = SMOTE(sampling_strategy=1.0, random_state=42)
X_resampled, y_resampled = smote.fit_resample(X_train, y_train)

# Treinar o modelo com o novo dataset balanceado
model.fit(X_resampled, y_resampled)

# Avaliar o modelo
y_pred_resampled = model.predict(X_test)
print(classification_report(y_test, y_pred_resampled))

from xgboost import XGBClassifier

model_xgb = XGBClassifier(scale_pos_weight=99, random_state=42)  # Ajuste o parâmetro para desbalanceamento
model_xgb.fit(X_train, y_train)

y_pred_xgb = model_xgb.predict(X_test)
print(classification_report(y_test, y_pred_xgb))

y_pred_proba = model.predict_proba(X_test)[:, 1]  # Probabilidade da classe 1
threshold = 0.3  # Ajuste esse valor conforme necessário
y_pred_adjusted = (y_pred_proba >= threshold).astype(int)

from sklearn.metrics import classification_report
print(classification_report(y_test, y_pred_adjusted))

from imblearn.over_sampling import SMOTE
from sklearn.ensemble import RandomForestClassifier


smote = SMOTE(random_state=42)
X_res, y_res = smote.fit_resample(X_train, y_train)

model = RandomForestClassifier(n_estimators=100, max_depth=10, n_jobs=-1, max_features="sqrt", random_state=42)
model.fit(X_res, y_res)

y_pred = model.predict(X_test)
print(classification_report(y_test, y_pred))

import matplotlib.pyplot as plt
from sklearn.metrics import precision_recall_curve, auc

# Função para calcular curva Precision-Recall e AUC
def plot_precision_recall_curves(models, X_test, y_test):
    plt.figure(figsize=(10, 7))

    for name, model in models.items():
        if hasattr(model, "predict_proba"):
            y_scores = model.predict_proba(X_test)[:, 1]
        else:
            # Modelos que não suportam predict_proba (fallback)
            y_scores = model.decision_function(X_test)

        precision, recall, _ = precision_recall_curve(y_test, y_scores)
        pr_auc = auc(recall, precision)
        plt.plot(recall, precision, label=f"{name} (AUC = {pr_auc:.2f})")

    plt.xlabel("Recall")
    plt.ylabel("Precision")
    plt.title("Precision-Recall Curves")
    plt.legend()
    plt.grid(True)
    plt.show()

# Aplicando aos seus modelos já definidos
plot_precision_recall_curves(
    {
        "Logistic Regression": model,           # Último modelo treinado foi RandomForest, mas reusaremos logistic depois
        "Random Forest": model,                 # Reutilizando a mesma variável para simplicidade
        "XGBoost": model_xgb
    },
    X_test,
    y_test
)

from sklearn.model_selection import RandomizedSearchCV
from xgboost import XGBClassifier
import numpy as np

param_dist = {
    'n_estimators': [50, 100, 200],
    'max_depth': [3, 5, 7, 10],
    'learning_rate': [0.01, 0.1, 0.2],
    'subsample': [0.6, 0.8, 1.0],
    'colsample_bytree': [0.6, 0.8, 1.0],
    'scale_pos_weight': [10, 50, 99, 150]  # importante para dados desbalanceados
}

xgb = XGBClassifier(random_state=42)
random_search = RandomizedSearchCV(
    estimator=xgb,
    param_distributions=param_dist,
    n_iter=30,
    scoring='f1',
    cv=3,
    verbose=1,
    n_jobs=-1
)

random_search.fit(X_res, y_res)
print("Melhores parâmetros:", random_search.best_params_)

from xgboost import XGBClassifier
from sklearn.metrics import classification_report

# Treinar modelo com melhores hiperparâmetros
best_model = XGBClassifier(
    subsample=1.0,
    scale_pos_weight=10,
    n_estimators=200,
    max_depth=7,
    learning_rate=0.2,
    colsample_bytree=0.8,
    random_state=42,
    eval_metric='logloss'
)
best_model.fit(X_res, y_res)  # Use dados balanceados (SMOTE)

# Avaliar no conjunto de teste original
y_pred_best = best_model.predict(X_test)
print(classification_report(y_test, y_pred_best))