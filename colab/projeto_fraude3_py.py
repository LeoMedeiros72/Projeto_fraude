# -*- coding: utf-8 -*-
"""Projeto_fraude3.py

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1Svb3MycozERcHu53-KHC1qWOK2T8OVgd
"""

# ====================== IMPORTAÇÕES ======================
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.model_selection import train_test_split, RandomizedSearchCV
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import (
    classification_report, precision_recall_curve, auc, confusion_matrix, ConfusionMatrixDisplay
)
from sklearn.linear_model import LogisticRegression
from sklearn.ensemble import RandomForestClassifier
from xgboost import XGBClassifier
from imblearn.over_sampling import SMOTE
import joblib

# ====================== CONEXÃO COM GOOGLE DRIVE ======================
from google.colab import drive
drive.mount('/content/drive')
data_path = "/content/drive/MyDrive/Projeto_Fraude/creditcard.csv"

# ====================== FUNÇÕES AUXILIARES ======================
def plot_precision_recall_curves(models, X_test, y_test):
    plt.figure(figsize=(10, 7))
    for name, model in models.items():
        if hasattr(model, "predict_proba"):
            y_scores = model.predict_proba(X_test)[:, 1]
        else:
            y_scores = model.decision_function(X_test)
        precision, recall, _ = precision_recall_curve(y_test, y_scores)
        pr_auc = auc(recall, precision)
        plt.plot(recall, precision, label=f"{name} (AUC = {pr_auc:.2f})")
    plt.xlabel("Recall")
    plt.ylabel("Precision")
    plt.title("Precision-Recall Curves")
    plt.legend()
    plt.grid(True)
    plt.show()

def predict_with_threshold(model, X, threshold=0.5):
    probs = model.predict_proba(X)[:, 1]
    return (probs >= threshold).astype(int)

def exibe_relatorio(model, X_test, y_test, nome_modelo):
    print(f"\n=== {nome_modelo} ===")
    y_pred = model.predict(X_test)
    print(classification_report(y_test, y_pred))
    ConfusionMatrixDisplay.from_estimator(model, X_test, y_test)
    plt.title(f"Matriz de Confusão - {nome_modelo}")
    plt.show()

# ====================== LEITURA E PRÉ-PROCESSAMENTO ======================
df = pd.read_csv(data_path)
print(df.head())
print("Valores ausentes:", df.isnull().sum().sum())

# Correlação
plt.figure(figsize=(12, 8))
sns.heatmap(df.corr(), annot=False, cmap='coolwarm')
plt.title("Mapa de Calor de Correlação")
plt.show()

# Separação de variáveis
X = df.drop("Class", axis=1)
y = df["Class"]

# Normalização
scaler = StandardScaler()
X_scaled = scaler.fit_transform(X)

# Separação treino/teste
X_train, X_test, y_train, y_test = train_test_split(
    X_scaled, y, test_size=0.2, random_state=42, stratify=y
)

# ====================== BALANCEAMENTO COM SMOTE ======================
smote = SMOTE(random_state=42)
X_res, y_res = smote.fit_resample(X_train, y_train)

# ====================== TREINAMENTO DOS MODELOS ======================

# Regressão Logística
model_logreg = LogisticRegression()
model_logreg.fit(X_res, y_res)

# Random Forest
model_rf = RandomForestClassifier(
    n_estimators=100, max_depth=10, n_jobs=-1, max_features="sqrt", random_state=42
)
model_rf.fit(X_res, y_res)

# XGBoost
model_xgb = XGBClassifier(scale_pos_weight=99, random_state=42)
model_xgb.fit(X_train, y_train)

from sklearn.metrics import precision_recall_curve, f1_score
import numpy as np

# Exibindo o relatório de classificação para cada modelo
def exibe_relatorio(model, X_test, y_test, nome_modelo):
    # Obter probabilidades de previsão para a classe 1 (fraude)
    y_pred_proba = model.predict_proba(X_test)[:, 1]

    # Calcular Precision, Recall e F1 para todos os thresholds possíveis
    precision, recall, thresholds = precision_recall_curve(y_test, y_pred_proba)

    # Calcular F1 para cada threshold
    f1_scores = 2 * (precision * recall) / (precision + recall)

    # Encontrar o threshold com o melhor F1-score
    best_threshold_index = np.argmax(f1_scores)
    best_threshold = thresholds[best_threshold_index]

    # Fazer previsões ajustadas com o melhor threshold
    y_pred_adjusted = (y_pred_proba >= best_threshold).astype(int)

    # Exibir o melhor threshold e o relatório de classificação
    print(f"Melhor threshold para {nome_modelo}: {best_threshold:.4f}")
    print(f"Relatório de Classificação para {nome_modelo}:")
    print(classification_report(y_test, y_pred_adjusted))

# ====================== AVALIAÇÃO DOS MODELOS ======================
exibe_relatorio(model_logreg, X_test, y_test, "Regressão Logística")
exibe_relatorio(model_rf, X_test, y_test, "Random Forest")
exibe_relatorio(model_xgb, X_test, y_test, "XGBoost")

from sklearn.metrics import precision_recall_curve, classification_report
import numpy as np

# Função para ajustar o threshold de qualquer modelo
def ajustar_threshold(model, X_test, y_test):
    # Obter probabilidades de previsão para a classe 1 (fraude)
    y_pred_proba = model.predict_proba(X_test)[:, 1]

    # Calcular Precision, Recall e F1 para todos os thresholds possíveis
    precision, recall, thresholds = precision_recall_curve(y_test, y_pred_proba)

    # Calcular F1 para cada threshold
    f1_scores = 2 * (precision * recall) / (precision + recall)

    # Encontrar o threshold com o melhor F1-score
    best_threshold_index = np.argmax(f1_scores)
    best_threshold = thresholds[best_threshold_index]

    # Fazer previsões ajustadas com o melhor threshold
    y_pred_adjusted = (y_pred_proba >= best_threshold).astype(int)

    # Exibir o melhor threshold e o relatório de classificação
    print(f"Melhor threshold: {best_threshold:.4f}")
    print(classification_report(y_test, y_pred_adjusted))

# Ajustar o threshold para cada modelo
print("=== Regressão Logística ===")
ajustar_threshold(model_logreg, X_test, y_test)

print("\n=== Random Forest ===")
ajustar_threshold(model_rf, X_test, y_test)

print("\n=== XGBoost ===")
ajustar_threshold(model_xgb, X_test, y_test)

# ====================== HYPERPARAMETER TUNING COM XGBOOST ======================
param_dist = {
    'n_estimators': [50, 100, 200],
    'max_depth': [3, 5, 7, 10],
    'learning_rate': [0.01, 0.1, 0.2],
    'subsample': [0.6, 0.8, 1.0],
    'colsample_bytree': [0.6, 0.8, 1.0],
    'scale_pos_weight': [10, 50, 99, 150]
}

xgb_search = RandomizedSearchCV(
    estimator=XGBClassifier(random_state=42),
    param_distributions=param_dist,
    n_iter=30,
    scoring='f1',
    cv=3,
    verbose=1,
    n_jobs=-1
)
xgb_search.fit(X_res, y_res)
print("Melhores parâmetros:", xgb_search.best_params_)

# Modelo com melhores parâmetros
best_xgb = XGBClassifier(
    **xgb_search.best_params_,
    random_state=42,
    eval_metric='logloss'
)
best_xgb.fit(X_res, y_res)
exibe_relatorio(best_xgb, X_test, y_test, "Melhor XGBoost Tunado")

# ====================== SALVAR O MODELO ======================
joblib.dump(best_xgb, '/content/drive/MyDrive/Projeto_Fraude/melhor_modelo_xgb.pkl')
print("Modelo salvo com sucesso.")